{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro-to-Keras\" data-toc-modified-id=\"Intro-to-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro to <code>Keras</code></a></span></li><li><span><a href=\"#Installing-Keras\" data-toc-modified-id=\"Installing-Keras-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Installing <code>Keras</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-the-GPU\" data-toc-modified-id=\"Using-the-GPU-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using the GPU</a></span></li></ul></li><li><span><a href=\"#Building-Keras-Models-:-ANN-Example\" data-toc-modified-id=\"Building-Keras-Models-:-ANN-Example-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building <code>Keras</code> Models : ANN Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Sequential-API\" data-toc-modified-id=\"The-Sequential-API-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Sequential API</a></span></li><li><span><a href=\"#The-Functional-API\" data-toc-modified-id=\"The-Functional-API-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>The Functional API</a></span></li></ul></li><li><span><a href=\"#Training-Keras-Models\" data-toc-modified-id=\"Training-Keras-Models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training <code>Keras</code> Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compiling-the-Network\" data-toc-modified-id=\"Compiling-the-Network-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Compiling the Network</a></span></li><li><span><a href=\"#Training-the-Network\" data-toc-modified-id=\"Training-the-Network-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Training the Network</a></span></li><li><span><a href=\"#Evaluating-and-Making-Predictions\" data-toc-modified-id=\"Evaluating-and-Making-Predictions-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Evaluating and Making Predictions</a></span></li></ul></li><li><span><a href=\"#Advanced-Keras-Layers\" data-toc-modified-id=\"Advanced-Keras-Layers-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Advanced <code>Keras</code> Layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dropout-Layers\" data-toc-modified-id=\"Dropout-Layers-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dropout Layers</a></span></li><li><span><a href=\"#Merge-Layers\" data-toc-modified-id=\"Merge-Layers-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Merge Layers</a></span></li><li><span><a href=\"#And-More...\" data-toc-modified-id=\"And-More...-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>And More...</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:37.709585Z",
     "start_time": "2019-05-31T22:25:33.825168Z"
    },
    "hidden": true,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/samiahmed/anaconda3/envs/metis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# some standard imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# keras specific\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "np.random.seed(22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to `Keras` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Keras is a high level neural networks API written in Python - capable of running on any major OS (Windows, MAC, and Linux compatible). It is a wrapper to Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Installing `Keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run this at the command line:\n",
    "\n",
    "```$ conda install -c conda-forge keras```\n",
    "\n",
    "If that doesn't work:\n",
    "\n",
    "```$ conda install tensorflow```\n",
    "\n",
    "... move into a folder for installing tools\n",
    "\n",
    "```$ git clone https://github.com/fchollet/keras.git```\n",
    "\n",
    "```$ cd keras```\n",
    "\n",
    "```$ python setup.py install```\n",
    "\n",
    "You can run this on your laptop, but it will be very slow. If you have a CUDA 7.5 compatable GPU (or use an AWS instance with one) keras will run way faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning requires tons of matrix computations. GPUs can do these really efficiently. \n",
    "\n",
    "If you're working on a computer with a GPU and want to configure it for keras:\n",
    "  - Install [CUDA](http://docs.nvidia.com/cuda/index.html#axzz4Pa5zY8Qi) \n",
    "  - In `.bashrc`/`.bash_profile`: `export THEANO_FLAGS=device=gpu,floatX=float32`\n",
    "\n",
    "But if not, don't worry, you can leverage virtual machine images, like an AMI from AWS. **When using AWS, a Deep Learning AMI such as [this one](https://aws.amazon.com/marketplace/pp/Amazon-Web-Services-AWS-Deep-Learning-AMI-Ubuntu-1/B07Y43P7X5), is highly recommended**-- use an AMI to get all the packages you need (including CUDA setup) handled up front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building `Keras` Models : ANN Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The core objects in `Keras` are `Models` and `Layers`\n",
    "- `Models` set up the container for your network\n",
    "- `Layers` fill in the architecture (connections, unit types, activation functions, etc.)\n",
    "- The 2 options for `Models`:\n",
    "  - `Sequential`: The basic one we'll focus on\n",
    "  - `Functional API`: Specify more complex models, more flexibility\n",
    "- There are lots of options for types of `Layers`. We'll start with two familiar ones:\n",
    "  - `Dense` layers are fully connected, meaning every node receives a linear combination of each node in its input layer.\n",
    "  - `Activation` layers apply an activation function to the value of each node in the previous layer.\n",
    "  - Alternatively, Dense layers may be created with an activation function as a parameter.\n",
    "  \n",
    "We'll look at how to build an ANN (Artificial Neural Network) using both the Sequential and Functional APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Sequential API\n",
    "\n",
    "Sequential Model is like a Sklearn object with extra features. Most importantly, it is an empty container that allows you to design whatever architecture you want (i.e., by adding `Layers`).\n",
    "\n",
    "Let's start filling it with layers. We can specify all of them at the time we create the model, or we can just create an empty container and add layers to it. Each method produces the same model, but the second one can be used to build models programatically, if you're interested in going that route.\n",
    "\n",
    "(See the [Keras Documentation on the Sequential API](https://keras.io/getting-started/sequential-model-guide/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:40.564438Z",
     "start_time": "2019-05-31T22:25:40.485943Z"
    },
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential model, all layers added at initialization\n",
    "model1 = Sequential([\n",
    "    Dense(32, input_dim=784),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:41.252749Z",
     "start_time": "2019-05-31T22:25:41.196491Z"
    },
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential model, empty at initialization, layers added later.\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=784)) # \n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Functional API\n",
    "\n",
    "The Functional API is a different approach to building models in keras. Each layer in a network is defined as a function that takes the previous layer as an input. Then the model is created by taking the input and output layers as parameters. \n",
    "\n",
    "Choosing between the Sequential and Functional APIs is usually a matter of personal preference, although there are some architectures that cannot be created using the Sequential API (notably siamese networks, in which a Merge layer combines the inputs from two paths of layers).\n",
    "\n",
    "(See the [Keras Documentation on the Functional API](https://keras.io/getting-started/functional-api-guide/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:42.199690Z",
     "start_time": "2019-05-31T22:25:42.147461Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Same as the Sequential models, but needs an explicit Input layer.\n",
    "# Note that each layer uses the same classes we used to create layers for our Sequential models,\n",
    "# but the layers are connected by passing them as parameters in layer function calls.\n",
    "# The model itself takes only the input and output layers as parameters.\n",
    "\n",
    "input_layer = Input(shape=(784,))\n",
    "hidden_layer = Dense(32)(input_layer)\n",
    "hidden_act = Activation('relu')(hidden_layer)\n",
    "output_layer = Dense(10)(hidden_act)\n",
    "output_act = Activation('softmax')(output_layer)\n",
    "\n",
    "model3 = Model(inputs=input_layer, outputs=output_act)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:42.812860Z",
     "start_time": "2019-05-31T22:25:42.751957Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Activations do not need to be included as separate layers.\n",
    "\n",
    "input_layer = Input(shape=(784,))\n",
    "hidden_layer = Dense(32, activation='relu')(input_layer)\n",
    "output_layer = Dense(10, activation='softmax')(hidden_layer)\n",
    "\n",
    "model4 = Model(inputs=input_layer, outputs=output_layer)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As can be seen from the summary printouts, these three models have the same architecture. The models built with the Functional API do have the benefit of having the Input dimensions included in the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training `Keras` Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sequential models and Models built with the functional API behave similarly, but there are some subtle differences. \n",
    "\n",
    "See the [Keras Models Documentation](https://keras.io/models/about-keras-models/) if you ever get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compiling the Network\n",
    "\n",
    "The `Model.compile()` function configures a model for training. In order to do this, we need to specify the loss function, the optimizer algorithm, and the metrics we wish to use to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:45.207781Z",
     "start_time": "2019-05-31T22:25:45.143235Z"
    },
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the network\n",
    "model4.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training the Network\n",
    "\n",
    "Similar to `sklearn`, we can train keras models by calling `fit` on `numpy` arrays.\n",
    "\n",
    "We can specify minibatch learning using the `epochs` and `batch_size` parameters.\n",
    "\n",
    "Below, we will load up the infamous MNIST dataset to keep our image classification theme going. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:18.389978Z",
     "start_time": "2019-05-31T22:25:45.890395Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1890 - accuracy: 0.9470\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1810 - accuracy: 0.9489\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1743 - accuracy: 0.9509\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1681 - accuracy: 0.9529\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1620 - accuracy: 0.9544\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1567 - accuracy: 0.9558\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1518 - accuracy: 0.9569\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1472 - accuracy: 0.9586\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1428 - accuracy: 0.9599\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1391 - accuracy: 0.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x65847f240>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import datasets\n",
    "\n",
    "# loading up the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1,784)/255 # reshape from 28x28 to 784 and\n",
    "X_test = X_test.reshape(-1,784)/255   # rescale from [0,255] to [0,1]\n",
    "\n",
    "# Fit the model \n",
    "model4.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating and Making Predictions\n",
    "\n",
    "Trained keras models have an `evaluate` method that returns the loss values and metrics values for the model in test mode. They also have a `predict` method for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:19.016762Z",
     "start_time": "2019-05-31T22:26:18.397079Z"
    },
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 46us/step\n",
      "\n",
      "Loss and Accuracy:\n",
      " [0.19392111354768277, 0.9455000162124634]\n",
      "\n",
      "Class Predictions:\n",
      " [[2.9800573e-05 2.3430900e-07 3.7246331e-04 ... 9.9428326e-01\n",
      "  5.9793372e-05 3.6907766e-04]\n",
      " [1.2797314e-03 3.1205046e-04 9.9172229e-01 ... 4.6964082e-09\n",
      "  1.0021380e-03 1.5780017e-08]\n",
      " [2.0203361e-05 9.8457277e-01 3.6254532e-03 ... 6.3381498e-03\n",
      "  1.2132559e-03 1.4855151e-04]\n",
      " ...\n",
      " [3.8872491e-07 4.6355896e-07 3.8032701e-06 ... 5.6317856e-04\n",
      "  1.5115299e-03 1.6416235e-02]\n",
      " [6.2488056e-05 1.3805726e-04 1.5524728e-04 ... 4.8040301e-06\n",
      "  2.2793479e-02 3.3265692e-06]\n",
      " [3.4258774e-05 1.0596973e-09 1.5840917e-04 ... 6.2076642e-09\n",
      "  2.9072743e-07 2.8535926e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "loss_and_metrics = model4.evaluate(X_test, y_test, batch_size=32)\n",
    "print('\\nLoss and Accuracy:\\n', loss_and_metrics)\n",
    "\n",
    "# Make Predictions\n",
    "classes = model4.predict(X_test, batch_size=32)\n",
    "#proba = model4.predict_proba(X_test, batch_size=32)\n",
    "print('\\nClass Predictions:\\n', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "... probably not a model we'll want to put into production, but at least we're able to train it and make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Advanced Keras Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dropout Layers\n",
    "\n",
    "Revisiting layers, they define:\n",
    "  - Nodes (number of features in a layer, and how they are connected to nodes in the previous layer)\n",
    "  - Activations (transformations applied to the data coming into a node from other nodes it is connected to) \n",
    "  - Other Properties (for example, reshaping the feature arrays, etc.)\n",
    "\n",
    "**Dropout** is a regularization technique used to control overfitting in neural networks. Instead of adding a penalty to our loss function, Dropout works by randomly setting some proportion of the weights between layers to zero. This prevents the layer from relying too heavily on any of its inputs.\n",
    "\n",
    "Here's an example of Dropout being used in an ANN that classifies documents from the Reuters newsgroups dataset. This approach can be used for image classification as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:45.142424Z",
     "start_time": "2019-05-31T22:26:19.021153Z"
    },
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 2s 212us/step - loss: 4.5277 - accuracy: 0.2218\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 1s 151us/step - loss: 4.7008 - accuracy: 0.2105\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 1s 150us/step - loss: 4.8681 - accuracy: 0.2109\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 1s 138us/step - loss: 4.7827 - accuracy: 0.2133\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 1s 140us/step - loss: 4.8075 - accuracy: 0.2103\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 1s 140us/step - loss: 4.7814 - accuracy: 0.2128\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 1s 142us/step - loss: 4.6141 - accuracy: 0.2164\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 1s 157us/step - loss: 4.7575 - accuracy: 0.2152\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 1s 142us/step - loss: 4.7160 - accuracy: 0.2165\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 1s 141us/step - loss: 4.7788 - accuracy: 0.2174\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 1s 144us/step - loss: 4.7081 - accuracy: 0.2141\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 1s 141us/step - loss: 4.7547 - accuracy: 0.2086\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 1s 140us/step - loss: 4.7122 - accuracy: 0.2124\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 1s 143us/step - loss: 4.7782 - accuracy: 0.2055\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 1s 160us/step - loss: 4.6845 - accuracy: 0.2096\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 1s 142us/step - loss: 4.7310 - accuracy: 0.2118\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 1s 144us/step - loss: 4.8294 - accuracy: 0.2168\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 1s 146us/step - loss: 4.7962 - accuracy: 0.2143\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 1s 147us/step - loss: 4.7258 - accuracy: 0.2080\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 1s 149us/step - loss: 4.7625 - accuracy: 0.2138\n",
      "2246/2246 [==============================] - 0s 115us/step\n"
     ]
    }
   ],
   "source": [
    "# Set the max number of words to keep, we are keeping 2000 most frequent \n",
    "max_features = 2000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "maxlen = 10\n",
    "\n",
    "# Data is stored in sentences, pad any that are shorter than 10 words with zeros\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# The 'kernel_initializer' parameter allows us to set the distribution of the\n",
    "# randomized weights that the layer is initialized with.\n",
    "model.add(Dense(64, input_dim=10, kernel_initializer=\"uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer=\"uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46, kernel_initializer=\"uniform\"))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Momentum: how much the weights are adjusted in response to the current gradient.\n",
    "# Nesterov momentum: weights are adjusted by gradient descent, but gradient is also corrected\n",
    "# after each step by examining the direction of the gradient at the new location.\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=16)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "...based on that accuracy, not a great performance; although with 46 classes that is understandable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merge Layers\n",
    "- Merge multiple layer sequences into a single layer\n",
    "- A number of options for merging outputs: `concat`, `sum`, `ave`, etc\n",
    "- Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:54.837753Z",
     "start_time": "2019-05-31T22:26:54.728898Z"
    },
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           25120       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           25120       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           650         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_branch_input = keras.layers.Input(shape=(784,))\n",
    "x1 = keras.layers.Dense(32, )(left_branch_input)\n",
    "\n",
    "right_branch_input = keras.layers.Input(shape=(784,))\n",
    "x2 = keras.layers.Dense(32)(right_branch_input)\n",
    "\n",
    "merged = keras.layers.concatenate([x1, x2])\n",
    "main_output = keras.layers.Dense(10, activation='sigmoid')(merged)\n",
    "\n",
    "model = keras.models.Model(inputs=[left_branch_input, right_branch_input], outputs=[main_output])\n",
    "\n",
    "# This is what the compile and training looks like\n",
    "# Note that to get this to run you will need to provide two sets of inputs, x_left and x_right\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## And More...\n",
    "\n",
    "Check out the [Keras Documentation on Layers](https://keras.io/layers/about-keras-layers/) to see what your options are. Keras provides lots (and lots, and lots) of options for ways to connect nodes between layers, for transforming or normalizing data, for specifying activation functions, and so on. If you're feeling brave, [you can also write your own layers](https://keras.io/layers/writing-your-own-keras-layers/)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "244.172px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
